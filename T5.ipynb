{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navidTerraNova/crossword-puzzle-clue-generation-using-LLMs/blob/main/T5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAxk-8PAe0KO"
      },
      "source": [
        "# **PACKAGES INSTALLATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9POjuf807PB"
      },
      "outputs": [],
      "source": [
        "!pip install rouge_score nltk transformers transformers[sentencepiece] datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH8SWciifJz1"
      },
      "source": [
        "# **MOUNTING GOOGLE DRIVE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbSBJLCu1hb3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svn77-2efjJ4"
      },
      "source": [
        "# **LOADING DATAFRAME**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPRIpyG11xJH"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/DataSet/nytcrosswords.csv\", encoding='latin1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7qZPP1qgOki"
      },
      "source": [
        "## **NAN VALUE CHECK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjkVuSuR1Wdf"
      },
      "outputs": [],
      "source": [
        "counter = 0\n",
        "for i in range(len(df[\"Word\"])):\n",
        "  if df[\"Word\"][i] == \"NAN\":\n",
        "    counter = counter + 1\n",
        "    print(\"found None Value\")\n",
        "    print(df[\"Word\"][i])\n",
        "    print(i)\n",
        "\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBVPsJjUf8uD"
      },
      "outputs": [],
      "source": [
        "counter = 0\n",
        "for i in range(len(df[\"Word\"])):\n",
        "  if df[\"Word\"][i] != df[\"Word\"][i] :\n",
        "    counter = counter + 1\n",
        "    print(\"found None Value\")\n",
        "    print(df[\"Word\"][i])\n",
        "    print(i)\n",
        "\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G6euKhBgdLK"
      },
      "source": [
        "# **DATA PREPROCESS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_Lg6VgCgZvT"
      },
      "outputs": [],
      "source": [
        "df = df.drop([\"Date\"], axis = 1)\n",
        "df[\"Word\"] = df[\"Word\"].str.lower()\n",
        "df = df[~df[\"Clue\"].str.contains(\"___\")]\n",
        "df = df.dropna()\n",
        "df = df[~df[\"Word\"].str.contains(\"nan\")]\n",
        "df = df.drop_duplicates()\n",
        "df = df.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IddHLYtQkZYo"
      },
      "outputs": [],
      "source": [
        "df = df.sample(frac=1, random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1h4KwITknLW"
      },
      "outputs": [],
      "source": [
        "df = df[:500000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPcq49_Kgogs"
      },
      "outputs": [],
      "source": [
        "df.to_csv('NYT-Crossword-Cleaned.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kp5wJTEgsNZ"
      },
      "source": [
        "# **LOADING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O-3RagWhzwQ"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"csv\", data_files = \"/content/NYT-Crossword-Cleaned.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFmXUQQOg7Lu"
      },
      "source": [
        "## **TRAIN_VALID_TEST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKD4XA5ljo1i"
      },
      "outputs": [],
      "source": [
        "dataset = dataset[\"train\"].train_test_split(test_size=0.02, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPk4c5G_1_m4"
      },
      "outputs": [],
      "source": [
        "datasets_train_validation = dataset[\"train\"].train_test_split(test_size=5000)\n",
        "\n",
        "dataset[\"train\"] = datasets_train_validation[\"train\"]\n",
        "dataset[\"validation\"] = datasets_train_validation[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "573L_as32TTd"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"] = dataset[\"train\"].shuffle().select(range(50000))\n",
        "dataset[\"validation\"] = dataset[\"validation\"].shuffle().select(range(2000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyNp1q-BhSDB"
      },
      "source": [
        "# **TOKENIZE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zQXqM-kjFBC"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "model_checkpoint = \"t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDLFHAyQivTO"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "\n",
        "  model_inputs = tokenizer(examples[\"Word\"], max_length = 16, truncation=True, padding = True)\n",
        "\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    labels = tokenizer(examples[\"Clue\"], max_length = 32, truncation=True, padding = True)\n",
        "\n",
        "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "  return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywKMfUtHu2hw"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = dataset.map(preprocess_function, batched = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "978hnB4GyBYt"
      },
      "outputs": [],
      "source": [
        "print(tokenized_datasets[\"train\"][\"Clue\"][2],tokenized_datasets[\"train\"][\"labels\"][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj9dZebAltl0"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j52bBbDQhnRD"
      },
      "source": [
        "# **SETTING TRAINING ARGUMENTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUgpblK83Fku"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0V4x6EN3V5i"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "model_name = \"FTT5-(500000)\"\n",
        "model_dir = f\"drive/MyDrive/Models/{model_name}\"\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    model_dir,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=2000,\n",
        "    learning_rate=4e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=4,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"rouge1\",\n",
        "    report_to=\"tensorboard\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFs3wKW0hx8C"
      },
      "source": [
        "# **METRIC SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9-SqObiQujA"
      },
      "outputs": [],
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric(\"rouge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__jWBhAQT94Z"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lReI3bBbQobW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip()))\n",
        "                      for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip()))\n",
        "                      for label in decoded_labels]\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels,\n",
        "                            use_stemmer=True)\n",
        "\n",
        "    # Extract ROUGE f1 scores\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "    # Add mean generated length to metrics\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id)\n",
        "                      for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEW3cSfuh62p"
      },
      "source": [
        "# **TRAINER API SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYmw3sUR3eNG"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tce1tMBl34MJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function that returns an untrained model to be trained\n",
        "def model_init():\n",
        "    return AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model_init=model_init,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJhta6ftez5V"
      },
      "source": [
        "# **PLOT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZHIOUoQ4JQk"
      },
      "outputs": [],
      "source": [
        "# Start TensorBoard before training to monitor it in progress\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '{model_dir}'/runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6BjAMfFykXL"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8UNoCGY4QwN"
      },
      "outputs": [],
      "source": [
        "trainer.train(resume_from_checkpoint=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySVAz3lYwynx"
      },
      "source": [
        "# **INFERENCE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieGOR7bFoGdN"
      },
      "outputs": [],
      "source": [
        "model_name = \"FTT5-(300000)/checkpoint-35000\"\n",
        "model_dir = f\"drive/MyDrive/Models/{model_name}\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
        "\n",
        "max_input_length = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAzCiggWoO9w"
      },
      "outputs": [],
      "source": [
        "for i in range(40):\n",
        "  inputs = \"history\"\n",
        "\n",
        "  inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
        "  output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=1, max_length=15)\n",
        "  decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
        "  predicted_title = nltk.sent_tokenize(decoded_output.strip())[0]\n",
        "\n",
        "  print(predicted_title)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNsVLac0r52CpreB7pnsOAf",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}